{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixPj8qS-Ls-z",
        "outputId": "16b846f7-4ffe-41b4-cc1f-112c7b8a27d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.data_utils import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 6 tane imaj \n",
        "# random seçicez\n",
        "# göstermesi\n",
        "\n",
        "for i in range(0,6):\n",
        "\n",
        "  rand_num = random.randint(0,len(x_train))\n",
        "  img = x_train[rand_num]\n",
        "  cv2_imshow(img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "s7XWBxTSLxbd",
        "outputId": "51785ceb-d401-46ef-b65d-0cade123ffc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F906054A650>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXUlEQVR4nM2PwQ3AIAwD3U6W0ehk0Mncb5wq/lRC9Q+O5Azwg0z2bDDBo0Dmq9MpCgxgOXi3TlGWyQFcvdMWciEZ6aiFtI+uDe3zgssVEijOovzwzwzDPQQ5Ld+RB5GIFBZJm9/8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F906055C150>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6UlEQVR4nGNgGLKAp+H/7A5vrFKM6Tf//v3792cgFjnxor9/P5448eDvA0w5ydN//+41YmAIur3RQwRdcuffvweEGBgYGCL//l2GLnn+7w9eiKv+/t0DFWOC0u46DN2fGRgYWJc9Z2D4i6Zx79+/kRIBJn1v/v79+9MBUxIGfpTBBFmg9Dyzj/cYGJ4siwtmeD8fwysGSgwMDAwMV//+fSaK6VEGBgYGBsfvf//W4pBj2Pn372cuOI8JRY6Zl4Hh4DccGm3+/v2bh+AyYShYi09yGz7JOTisZLD5+/ciMy5JhUd/w3DJkQQAmYhb8OckVfwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F906054AFD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhUlEQVR4nMXR0QnDMAwEUOnIGKVr1NmjoWMEukjHajNGIGQJ41N/ZcP9tvcnng+MZPbvLG3OI3rlqrFgeJzT6l7SOGWbYdeLwpW0UAgYXCGHZvc7d7grjGDkZh823lXThmaPG7yYylJblU2DQyODT4XH6bgpfD+CodA+W17ueNwX9Yp+ki+o4CyRDt1O+wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9053011DD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3ElEQVR4nN2PsWrCYBSFP0MLDoUsHZy6CiI2Y8GCGfMKDgpCZ0ddfINCH6GFzEUIhUK3DnmHFtLMSnBxPvyJg4Vo9b5A73C5nI9zz73wb6rxV2hFzL7e0p9j2GrCS4Xf80qYP9UwHNAY3YBX8tsuAS6AxcT399JnxfcjTKd1pisBr5hDDMD1R692xlWSHN4UBaTWA9FGGltwKWW359Fd7pR1DF8stzJ8BIXL2gbr5pLFglx6tQ4tpPTKYA9OGhosdFVu7eRd25HFwo2ejxWvHgc+99YbBGv1zcjT2gFm9UZpjZ7aDwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F90E34B3C50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABB0lEQVR4nMXPMUhCQRzH8a8iKvmIKCHEoYasTZegyKGl1U2hIXQTRFprCUHaHk7N0dDS5OQUFNEaRA0ivBCxcBDelDQocfcaHkh3cm3Sb7nj/7n/n//B3OM9rRqtIkXLMtiCc1EdpQ24J+JsmaY2xUwpOL0lA3+g5wGw8eC67mFIfbXy8QKw+Dq0i1efDRVT4hqgPj4AjnpL6lg/2/d3wO1yXMVAH7AyNwBuV19oHcgm/LXWNARg0z/2++8ahgFwgMhu+1vpiXUEcCwAzgYpbc+8PIGcTBI7lZeaEW1MzjMJUas+TsoRHaH0Nu4KObQL09/9VmsnnM7L3Cj0Ndvpx3aeKyb77/wA5fxIPycHGZAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9053011E10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4UlEQVR4nGNgGBmAkYGBgYFBtzABwvv/qY2BYdYHZBULPv5FBm9eXY5E6Pz3n4GB4c8OBgYGCxGI8r8Z82CStZ69rxj+HmNgYNAVYGCwaGRnYLivgt0Zlu/+/v07n4GBgYEJU5KViYHhzQQcHlj39+8LfexSzPnf/j7Sw6Gv6e/fB4Y45HTX/X1ohEPO7tnfZ1U45Gye/f2Jyz7zl3//LMUhZ/bh7995uOQ+//370hS7HOuqv3//LsCh0eDv37/H+VGE4GEruZ6BgeH2R+waFb7+/ZInhCrGCGe56Z3bh6YBALdrWUIjrAHSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows=x_train[0].shape[0]\n",
        "img_cols=x_train[1].shape[1]\n",
        "\n",
        "x_train=x_train.reshape(len(x_train),img_rows,img_cols,1)\n",
        "x_test=x_test.reshape(len(x_test),img_rows,img_cols,1)\n",
        "\n",
        "x_train=x_train.astype(\"float32\")\n",
        "x_test=x_test.astype(\"float32\")\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRnvnROJLz3E",
        "outputId": "fb8ef936-a6f1-477d-9d7b-515c4f67918c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)\n",
        "\n",
        "y_test\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IYsBy4XL7tK",
        "outputId": "19079a5a-6e4e-4dcb-f162-fd96ff5f1b00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "34JYijMVMAw6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmECSZZmMA8E",
        "outputId": "d5e61f7c-cbef-4486-9241-e593def5b36d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1638656   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,728,586\n",
            "Trainable params: 1,728,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = [32,64,128,256,512,1024]\n",
        "epochs = 10\n",
        "\n",
        "for i in batch_size:\n",
        "    history = model.fit(x_train, y_train, batch_size=i,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW84fUz5MBEB",
        "outputId": "ea68abc9-b8a9-45b2-9a47-3ccbf403c5dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2863 - accuracy: 0.9158 - val_loss: 0.1757 - val_accuracy: 0.9473\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2792 - accuracy: 0.9180 - val_loss: 0.1730 - val_accuracy: 0.9484\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2745 - accuracy: 0.9186 - val_loss: 0.1696 - val_accuracy: 0.9491\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2701 - accuracy: 0.9195 - val_loss: 0.1671 - val_accuracy: 0.9500\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2646 - accuracy: 0.9220 - val_loss: 0.1638 - val_accuracy: 0.9515\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2574 - accuracy: 0.9238 - val_loss: 0.1613 - val_accuracy: 0.9518\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2563 - accuracy: 0.9240 - val_loss: 0.1592 - val_accuracy: 0.9528\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2559 - accuracy: 0.9250 - val_loss: 0.1574 - val_accuracy: 0.9533\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2475 - accuracy: 0.9266 - val_loss: 0.1550 - val_accuracy: 0.9541\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2481 - accuracy: 0.9276 - val_loss: 0.1523 - val_accuracy: 0.9553\n",
            "Test loss: 0.1523207575082779\n",
            "Test accuracy: 0.955299973487854\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2451 - accuracy: 0.9273 - val_loss: 0.1510 - val_accuracy: 0.9555\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2394 - accuracy: 0.9293 - val_loss: 0.1492 - val_accuracy: 0.9558\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.2386 - accuracy: 0.9291 - val_loss: 0.1484 - val_accuracy: 0.9559\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2350 - accuracy: 0.9306 - val_loss: 0.1463 - val_accuracy: 0.9565\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.2337 - accuracy: 0.9311 - val_loss: 0.1445 - val_accuracy: 0.9569\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2321 - accuracy: 0.9315 - val_loss: 0.1439 - val_accuracy: 0.9573\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2302 - accuracy: 0.9327 - val_loss: 0.1416 - val_accuracy: 0.9580\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.2261 - accuracy: 0.9335 - val_loss: 0.1400 - val_accuracy: 0.9584\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2252 - accuracy: 0.9344 - val_loss: 0.1385 - val_accuracy: 0.9588\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2224 - accuracy: 0.9349 - val_loss: 0.1378 - val_accuracy: 0.9586\n",
            "Test loss: 0.1378444880247116\n",
            "Test accuracy: 0.9585999846458435\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2220 - accuracy: 0.9357 - val_loss: 0.1367 - val_accuracy: 0.9596\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2180 - accuracy: 0.9352 - val_loss: 0.1359 - val_accuracy: 0.9594\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2177 - accuracy: 0.9360 - val_loss: 0.1352 - val_accuracy: 0.9597\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2155 - accuracy: 0.9367 - val_loss: 0.1340 - val_accuracy: 0.9598\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2141 - accuracy: 0.9374 - val_loss: 0.1326 - val_accuracy: 0.9605\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2111 - accuracy: 0.9381 - val_loss: 0.1322 - val_accuracy: 0.9609\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2088 - accuracy: 0.9388 - val_loss: 0.1313 - val_accuracy: 0.9606\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2084 - accuracy: 0.9391 - val_loss: 0.1304 - val_accuracy: 0.9613\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2087 - accuracy: 0.9378 - val_loss: 0.1294 - val_accuracy: 0.9611\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2076 - accuracy: 0.9388 - val_loss: 0.1287 - val_accuracy: 0.9611\n",
            "Test loss: 0.12871801853179932\n",
            "Test accuracy: 0.9610999822616577\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.2089 - accuracy: 0.9389 - val_loss: 0.1282 - val_accuracy: 0.9614\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.2029 - accuracy: 0.9403 - val_loss: 0.1271 - val_accuracy: 0.9620\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.2032 - accuracy: 0.9401 - val_loss: 0.1268 - val_accuracy: 0.9616\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.2027 - accuracy: 0.9396 - val_loss: 0.1263 - val_accuracy: 0.9624\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.2024 - accuracy: 0.9409 - val_loss: 0.1257 - val_accuracy: 0.9624\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.2018 - accuracy: 0.9407 - val_loss: 0.1251 - val_accuracy: 0.9626\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1987 - accuracy: 0.9410 - val_loss: 0.1245 - val_accuracy: 0.9626\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.2005 - accuracy: 0.9410 - val_loss: 0.1240 - val_accuracy: 0.9623\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1972 - accuracy: 0.9420 - val_loss: 0.1231 - val_accuracy: 0.9628\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1964 - accuracy: 0.9424 - val_loss: 0.1227 - val_accuracy: 0.9630\n",
            "Test loss: 0.12270753085613251\n",
            "Test accuracy: 0.9629999995231628\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 4s 30ms/step - loss: 0.1969 - accuracy: 0.9420 - val_loss: 0.1225 - val_accuracy: 0.9630\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1962 - accuracy: 0.9422 - val_loss: 0.1220 - val_accuracy: 0.9631\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1955 - accuracy: 0.9423 - val_loss: 0.1215 - val_accuracy: 0.9630\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1934 - accuracy: 0.9427 - val_loss: 0.1212 - val_accuracy: 0.9632\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1961 - accuracy: 0.9422 - val_loss: 0.1210 - val_accuracy: 0.9633\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 30ms/step - loss: 0.1946 - accuracy: 0.9430 - val_loss: 0.1208 - val_accuracy: 0.9633\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1946 - accuracy: 0.9428 - val_loss: 0.1205 - val_accuracy: 0.9630\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1921 - accuracy: 0.9434 - val_loss: 0.1199 - val_accuracy: 0.9636\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1930 - accuracy: 0.9435 - val_loss: 0.1199 - val_accuracy: 0.9635\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1921 - accuracy: 0.9423 - val_loss: 0.1195 - val_accuracy: 0.9633\n",
            "Test loss: 0.1195320412516594\n",
            "Test accuracy: 0.9632999897003174\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 3s 56ms/step - loss: 0.1920 - accuracy: 0.9435 - val_loss: 0.1193 - val_accuracy: 0.9636\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 3s 53ms/step - loss: 0.1911 - accuracy: 0.9429 - val_loss: 0.1190 - val_accuracy: 0.9634\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 3s 53ms/step - loss: 0.1884 - accuracy: 0.9436 - val_loss: 0.1186 - val_accuracy: 0.9633\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 3s 53ms/step - loss: 0.1892 - accuracy: 0.9452 - val_loss: 0.1186 - val_accuracy: 0.9635\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1882 - accuracy: 0.9442 - val_loss: 0.1185 - val_accuracy: 0.9635\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 3s 53ms/step - loss: 0.1912 - accuracy: 0.9444 - val_loss: 0.1182 - val_accuracy: 0.9638\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1900 - accuracy: 0.9443 - val_loss: 0.1181 - val_accuracy: 0.9637\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1881 - accuracy: 0.9444 - val_loss: 0.1178 - val_accuracy: 0.9637\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1866 - accuracy: 0.9449 - val_loss: 0.1175 - val_accuracy: 0.9637\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1876 - accuracy: 0.9459 - val_loss: 0.1175 - val_accuracy: 0.9636\n",
            "Test loss: 0.11749637126922607\n",
            "Test accuracy: 0.9635999798774719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = [32,64,128,256,512,1024]\n",
        "epochs = 10\n",
        "history = [1,2,3,4,5,6]\n",
        "\n",
        "for i in range(6):\n",
        "    history[i] = model.fit(x_train, y_train, batch_size=batch_size[i],epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "Wkw-XETbVZXq",
        "outputId": "a758d40f-9bc4-4a72-b217-70b1f8333fa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1884 - accuracy: 0.9435 - val_loss: 0.1163 - val_accuracy: 0.9643\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1879 - accuracy: 0.9455 - val_loss: 0.1157 - val_accuracy: 0.9640\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1854 - accuracy: 0.9457 - val_loss: 0.1151 - val_accuracy: 0.9645\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1799 - accuracy: 0.9466 - val_loss: 0.1144 - val_accuracy: 0.9651\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1858 - accuracy: 0.9460 - val_loss: 0.1128 - val_accuracy: 0.9650\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1810 - accuracy: 0.9471 - val_loss: 0.1121 - val_accuracy: 0.9651\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1777 - accuracy: 0.9469 - val_loss: 0.1115 - val_accuracy: 0.9651\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1772 - accuracy: 0.9477 - val_loss: 0.1105 - val_accuracy: 0.9657\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1757 - accuracy: 0.9481 - val_loss: 0.1100 - val_accuracy: 0.9656\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1763 - accuracy: 0.9486 - val_loss: 0.1087 - val_accuracy: 0.9662\n",
            "Test loss: 0.10866335779428482\n",
            "Test accuracy: 0.9661999940872192\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1735 - accuracy: 0.9494 - val_loss: 0.1078 - val_accuracy: 0.9665\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1732 - accuracy: 0.9495 - val_loss: 0.1073 - val_accuracy: 0.9664\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.1698 - accuracy: 0.9511 - val_loss: 0.1064 - val_accuracy: 0.9665\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.1702 - accuracy: 0.9501 - val_loss: 0.1059 - val_accuracy: 0.9670\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.1677 - accuracy: 0.9506 - val_loss: 0.1052 - val_accuracy: 0.9667\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1674 - accuracy: 0.9515 - val_loss: 0.1045 - val_accuracy: 0.9669\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1642 - accuracy: 0.9520 - val_loss: 0.1036 - val_accuracy: 0.9670\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1648 - accuracy: 0.9510 - val_loss: 0.1029 - val_accuracy: 0.9671\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1649 - accuracy: 0.9522 - val_loss: 0.1024 - val_accuracy: 0.9672\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1609 - accuracy: 0.9533 - val_loss: 0.1019 - val_accuracy: 0.9672\n",
            "Test loss: 0.10193531960248947\n",
            "Test accuracy: 0.967199981212616\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1622 - accuracy: 0.9524 - val_loss: 0.1015 - val_accuracy: 0.9672\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1622 - accuracy: 0.9518 - val_loss: 0.1008 - val_accuracy: 0.9678\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1604 - accuracy: 0.9527 - val_loss: 0.1002 - val_accuracy: 0.9682\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1589 - accuracy: 0.9528 - val_loss: 0.1002 - val_accuracy: 0.9676\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1568 - accuracy: 0.9544 - val_loss: 0.0992 - val_accuracy: 0.9681\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1590 - accuracy: 0.9539 - val_loss: 0.0989 - val_accuracy: 0.9680\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1576 - accuracy: 0.9548 - val_loss: 0.0984 - val_accuracy: 0.9681\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1560 - accuracy: 0.9549 - val_loss: 0.0982 - val_accuracy: 0.9683\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1568 - accuracy: 0.9538 - val_loss: 0.0978 - val_accuracy: 0.9683\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1564 - accuracy: 0.9546 - val_loss: 0.0971 - val_accuracy: 0.9687\n",
            "Test loss: 0.09711682796478271\n",
            "Test accuracy: 0.9686999917030334\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.1545 - accuracy: 0.9545 - val_loss: 0.0971 - val_accuracy: 0.9692\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1518 - accuracy: 0.9554 - val_loss: 0.0969 - val_accuracy: 0.9690\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1519 - accuracy: 0.9553 - val_loss: 0.0964 - val_accuracy: 0.9689\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1516 - accuracy: 0.9551 - val_loss: 0.0963 - val_accuracy: 0.9692\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1532 - accuracy: 0.9548 - val_loss: 0.0957 - val_accuracy: 0.9699\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1530 - accuracy: 0.9554 - val_loss: 0.0959 - val_accuracy: 0.9692\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1519 - accuracy: 0.9554 - val_loss: 0.0953 - val_accuracy: 0.9700\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1535 - accuracy: 0.9556 - val_loss: 0.0951 - val_accuracy: 0.9693\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1524 - accuracy: 0.9555 - val_loss: 0.0949 - val_accuracy: 0.9697\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1509 - accuracy: 0.9557 - val_loss: 0.0945 - val_accuracy: 0.9696\n",
            "Test loss: 0.09452348947525024\n",
            "Test accuracy: 0.9696000218391418\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1489 - accuracy: 0.9566 - val_loss: 0.0942 - val_accuracy: 0.9701\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1488 - accuracy: 0.9561 - val_loss: 0.0941 - val_accuracy: 0.9698\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1492 - accuracy: 0.9559 - val_loss: 0.0940 - val_accuracy: 0.9699\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1486 - accuracy: 0.9564 - val_loss: 0.0942 - val_accuracy: 0.9701\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1477 - accuracy: 0.9567 - val_loss: 0.0934 - val_accuracy: 0.9698\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 30ms/step - loss: 0.1514 - accuracy: 0.9553 - val_loss: 0.0931 - val_accuracy: 0.9703\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1505 - accuracy: 0.9557 - val_loss: 0.0927 - val_accuracy: 0.9703\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.1458 - accuracy: 0.9564 - val_loss: 0.0927 - val_accuracy: 0.9702\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 4s 34ms/step - loss: 0.1486 - accuracy: 0.9563 - val_loss: 0.0928 - val_accuracy: 0.9702\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 4s 33ms/step - loss: 0.1476 - accuracy: 0.9563 - val_loss: 0.0924 - val_accuracy: 0.9703\n",
            "Test loss: 0.09244110435247421\n",
            "Test accuracy: 0.970300018787384\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1459 - accuracy: 0.9573 - val_loss: 0.0924 - val_accuracy: 0.9706\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 3s 52ms/step - loss: 0.1466 - accuracy: 0.9573 - val_loss: 0.0923 - val_accuracy: 0.9707\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1481 - accuracy: 0.9563 - val_loss: 0.0923 - val_accuracy: 0.9703\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 3s 53ms/step - loss: 0.1440 - accuracy: 0.9579 - val_loss: 0.0920 - val_accuracy: 0.9705\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 3s 55ms/step - loss: 0.1462 - accuracy: 0.9574 - val_loss: 0.0920 - val_accuracy: 0.9708\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 3s 53ms/step - loss: 0.1448 - accuracy: 0.9577 - val_loss: 0.0918 - val_accuracy: 0.9710\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 3s 54ms/step - loss: 0.1438 - accuracy: 0.9585 - val_loss: 0.0917 - val_accuracy: 0.9706\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 3s 54ms/step - loss: 0.1448 - accuracy: 0.9570 - val_loss: 0.0915 - val_accuracy: 0.9712\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 3s 56ms/step - loss: 0.1447 - accuracy: 0.9575 - val_loss: 0.0913 - val_accuracy: 0.9713\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 3s 54ms/step - loss: 0.1455 - accuracy: 0.9571 - val_loss: 0.0913 - val_accuracy: 0.9713\n",
            "Test loss: 0.0912846103310585\n",
            "Test accuracy: 0.9713000059127808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history[0].history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "line1 = plt.plot(epochs, val_loss_values, label='Validation/Test loss')\n",
        "line2 = plt.plot(epochs, loss_values, label='Training loss')\n",
        "plt.setp(line1, linewidth=2.0, marker='+', markersize=10.0)\n",
        "plt.setp(line2, linewidth=2.0, marker='4', markersize=10.0)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7yPhDeSsX3hA",
        "outputId": "98bfea99-a7bb-4caa-f04c-67a92c704481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}